# -*- coding: utf-8 -*-
"""DecisionStumpBase.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lKW4-Y9NjkyiVpnw8qTOl4wyI-Q1zQLp

Here is data and some base code for the decision stump problem in PS#9

Just below is python you are recommended to use.  Feel free to redefine the data table as a numpy array if you are more familiar with that.

Further down is older C++ code (no guaranteed); it also uses different, older functions that were defined in R&N Third edition.
"""



# Decision Stump Code Base
# MS Branicky, 2020-04-01

# 1. Title: 1984 United States Congressional Voting Records Database
# 
# 2. Source Information:
#     (a) Source:  Congressional Quarterly Almanac, 98th Congress, 
#                  2nd session 1984, Volume XL: Congressional Quarterly Inc. 
#                  Washington, D.C., 1985.
#     (b) Donor: Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
#     (c) Date: 27 April 1987 
# 
# 4. Relevant Information:
#       This data set includes votes for each of the U.S. House of
#       Representatives Congressmen on the 16 key votes identified by the
#       CQA.  The CQA lists nine different types of votes: voted for, paired
#       for, and announced for (these three simplified to yea), voted
#       against, paired against, and announced against (these three
#       simplified to nay), voted present, voted present to avoid conflict
#       of interest, and did not vote or otherwise make a position known
#       (these three simplified to an unknown disposition).
#
# 5. Number of Instances: 435 (267 democrats, 168 republicans)
#
# MSB NOTE: Any voting record (instance) that contained >=1 unknowns was removed.
# MSB NOTE: This left only 232 of the original 435 instances.
#
# 6. Number of Attributes: 16 + class name = 17 (all Boolean valued)
#
# MSB NOTE: All attribute values were changed to 0s and 1s as noted below
#
# 7. Attribute Information:
#   1. Class Name: 2 (0=democrat, 1=republican)
#   2. handicapped-infants: 2 (1=y,0=n)
#   3. water-project-cost-sharing: 2 (1=y,0=n)
#   4. adoption-of-the-budget-resolution: 2 (1=y,0=n)
#   5. physician-fee-freeze: 2 (1=y,0=n)
#   6. el-salvador-aid: 2 (1=y,0=n)
#   7. religious-groups-in-schools: 2 (1=y,0=n)
#   8. anti-satellite-test-ban: 2 (1=y,0=n)
#   9. aid-to-nicaraguan-contras: 2 (1=y,0=n)
#  10. mx-missile: 2 (1=y,0=n)
#  11. immigration: 2 (1=y,0=n)
#  12. synfuels-corporation-cutback: 2 (1=y,0=n)
#  13. education-spending: 2 (1=y,0=n)
#  14. superfund-right-to-sue: 2 (1=y,0=n)
#  15. crime: 2 (1=y,0=n)
#  16. duty-free-exports: 2 (1=y,0=n)
#  17. export-administration-act-south-africa: 2 (1=y,0=n)
#
"""
othertable=[
    [0,0,1,1,0,1,1,0,0,0,0,0,0,1,1,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1]
]
"""
N=232

othertable=[
    [0,0,1,1,0,1,1,0,0,0,0,0,0,1,1,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [1,1,0,0,1,1,0,1,1,1,0,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,1,1,1,0,0,0,1,1,1,1,0,0,1,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,1,1,0,1,1,1,0,0,0,0,0,0,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,1,0,1,0,0,0,1,1,1,1,1,0,1,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [0,1,1,1,0,0,0,1,1,0,0,0,0,0,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [1,1,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [1,0,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0],
    [1,0,1,0,1,1,1,0,0,0,1,1,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,0,1],
    [1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,1,0,0,0,1,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,1],
    [1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,0,1],
    [0,1,0,1,0,0,1,1,1,1,1,1,0,0,1,1,1],
    [0,0,1,1,1,1,1,0,0,0,1,1,0,1,1,0,0],
    [0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1],
    [0,1,1,1,0,1,1,0,0,0,1,1,0,1,1,0,1],
    [1,0,0,0,1,1,0,0,0,0,1,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,0,0,1,0,1,1,0,0,0,1,1,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,0,1,1,0,1,1,1,0,1,1,1,0,1,1,0,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,1,1],
    [0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,0,1],
    [0,1,0,0,0,1,1,1,0,0,1,1,0,0,1,0,1],
    [0,1,1,1,0,0,1,1,1,1,1,0,0,0,0,0,1],
    [0,1,0,0,0,1,1,0,0,0,0,1,1,0,1,0,1],
    [0,1,0,1,0,1,1,1,0,0,0,1,0,0,1,0,1],
    [0,1,1,1,0,0,0,0,1,1,0,1,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [1,1,1,1,1,1,0,1,0,0,0,0,1,1,1,0,1],
    [0,0,1,1,0,0,0,0,1,1,1,1,0,0,0,1,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,0,1,0,1],
    [0,0,0,1,0,0,1,0,1,1,1,0,0,0,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,0,1],
    [0,0,0,1,0,0,1,1,1,1,1,0,0,0,1,0,1],
    [0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,1,1],
    [1,0,0,0,1,0,0,1,1,1,1,0,0,1,1,0,1],
    [1,0,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,1,1],
    [1,0,1,0,1,1,1,0,0,0,1,1,1,1,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,1,0,0,1,0,1,1],
    [1,1,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [0,0,1,1,0,0,1,0,1,1,1,1,0,1,0,1,1],
    [0,0,0,1,0,0,1,1,1,1,1,1,0,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,0,0],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,0,1,0,0,1,1,0,0,0,0,0,1,1,1,1,1],
    [0,0,0,0,0,1,1,1,0,0,0,0,1,1,1,0,1],
    [0,0,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1],
    [1,0,1,0,1,1,1,1,0,0,0,0,1,1,1,0,1],
    [1,1,0,1,1,1,1,1,1,0,1,0,1,0,1,1,1],
    [1,1,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,1,0,0,1,0,1],
    [0,0,0,0,0,1,1,0,0,0,1,1,1,1,1,0,1],
    [0,0,1,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [1,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [0,0,1,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,0,0,0,0,0,1,1,1,1,0,1,0,0,1,1,1],
    [0,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,0,0,1,0,0,0,1,1,1,0,0,0,0,1,1,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,0,1,0,0,1,1,1,1,1,1,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [1,0,0,1,1,1,1,1,0,0,0,0,1,1,1,0,1],
    [0,0,0,1,0,0,1,1,1,1,1,0,1,0,0,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,0,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,0,1],
    [0,0,0,1,0,0,1,1,1,1,0,0,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [0,0,1,1,0,0,1,0,1,1,0,1,0,1,0,1,1],
    [1,1,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,0,1,1,0,0,0,0,1,1,0,1,0,0,1,1,1],
    [1,0,0,0,1,1,0,0,0,0,0,0,1,1,1,0,1],
    [0,0,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1],
    [1,0,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,1,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,0,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,0,1,0,0,1,1,1,0,0,0,1,1,0,0,1],
    [1,0,0,0,1,1,1,1,0,0,1,0,0,0,1,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,1,0,0,1,1,1],
    [0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,1,1,1],
    [1,0,0,0,1,1,0,0,0,0,0,0,1,0,1,0,0],
    [0,0,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,0,1,0,1],
    [1,1,0,0,0,0,0,1,1,1,1,0,0,0,1,0,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [1,1,0,0,1,1,0,1,0,0,1,0,0,0,1,1,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,1,0],
    [1,0,0,1,1,1,1,1,1,0,1,0,0,0,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,0,0,1,0,0,0,1,1,1,1,0,0,0,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,0,0,1,0,0,1,1,1,1,1,1,0,0,0,1,1],
    [0,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1],
    [0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,1,1],
    [0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1],
    [1,0,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1],
    [0,0,1,0,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [0,0,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1],
    [1,0,0,0,1,1,0,1,1,1,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,1,0,0,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,1,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,1,0],
    [0,0,0,1,0,0,1,1,1,1,1,0,0,1,0,0,1],
    [0,1,1,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1],
    [0,0,0,0,0,0,1,0,1,1,0,1,1,1,1,1,0],
    [0,1,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,1,0,0,1,0,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,1,1,1,1,0,0],
    [0,1,1,0,1,0,0,1,1,1,0,1,0,0,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [0,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,1,1,1],
    [1,1,0,0,1,1,1,0,0,0,0,1,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,1,1,1,0,1,0,1],
    [1,0,0,0,1,1,0,1,0,1,1,0,0,0,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0,1,1],
    [1,0,0,0,1,1,1,1,0,0,1,0,1,0,1,1,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,1,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0],
    [1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1],
    [0,0,1,0,0,0,1,1,0,1,0,1,0,0,0,1,1],
    [1,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1],
    [1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1],
    [1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [0,1,0,1,0,0,1,1,1,1,1,0,0,1,0,0,1],
    [0,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1],
    [1,1,1,0,1,1,1,0,0,0,1,1,0,1,0,0,0],
    [1,1,1,0,1,1,1,0,0,0,0,1,0,1,1,0,1],
    [0,0,1,0,0,1,1,0,0,0,1,1,0,1,1,0,0],
    [0,0,1,1,0,0,1,1,1,0,1,0,0,0,0,1,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,0,1,1,0,1],
    [1,0,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,0,1,0,1,1,1,0,0,0,0,1,1,0,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,1,1,0,1,1,0,1,1,1,1,0,0,0,0,1],
    [0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,1],
    [0,1,1,0,0,1,1,0,0,0,0,1,1,1,1,1,0],
    [0,1,1,0,0,0,0,0,1,1,0,1,0,0,0,1,0],
    [1,1,1,0,1,1,1,0,0,0,0,1,1,1,1,0,1],
    [0,1,1,1,0,1,1,0,1,0,0,1,0,1,0,1,1],
    [0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,1],
    [1,0,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0],
    [1,1,1,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1],
    [0,1,0,1,0,1,1,0,0,1,1,0,0,1,1,0,1],
    [0,0,0,0,1,1,1,0,0,0,0,1,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,0],
    [1,0,0,0,1,1,1,0,0,0,0,1,1,1,1,0,1],
    [0,1,0,1,0,0,1,1,1,1,1,1,0,0,0,0,1],
    [1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [1,1,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1],
    [0,1,1,1,0,0,0,1,1,1,1,1,0,1,0,0,1],
    [0,1,1,1,0,0,0,1,1,0,1,0,0,0,0,0,1],
    [0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0,1],
    [1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,1],
    [0,0,1,1,0,1,1,1,1,0,0,1,0,1,0,1,1],
    [0,0,0,1,0,0,1,1,1,1,0,1,0,0,0,1,1],
    [0,0,1,1,0,0,1,1,1,1,0,1,0,0,1,1,1],
    [0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1],
    [1,0,0,0,1,1,1,1,1,0,1,0,1,1,1,0,1],
    [1,0,0,1,1,1,1,0,0,1,1,0,1,1,1,0,1],
    [0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1],
]

from math import log2

def B(q):  
  if q==0 or q==1:
    return 0
  return -(q*log2(q)+(1-q)*log2(1-q))

def remainder(a):
  
  yes = sum([othertable[i][a] for i in range(len(othertable))])
  no = sum([othertable[i][a] == 0 for i in range(len(othertable))])

  for i in range(len(othertable)):
    classification = othertable[i][0]
    
    attribute = othertable[i][a]

    #dem - pos
    if classification == 0 and attribute == 1:
        dem_pos[a] +=1
    #rep - pos
    if classification == 1 and attribute == 1:
        rep_pos[a] +=1
    #dem - neg
    if classification == 0 and attribute == 0:
        dem_neg[a] +=1
    #rep - neg
    if classification == 1 and attribute == 0:
        rep_neg[a] +=1
        

  total = yes + no

  #if zero reps
  if yes == 0:
    pos_entropy = 0
  else:

    pos_entropy = B(rep_pos[a]/(rep_pos[a]+rep_neg[a]))
  #if zero dems
  if no == 0:
    neg_entropy = 0
  else:

    neg_entropy = B(dem_pos[a]/(dem_pos[a]+dem_neg[a]))
  
  return((yes/total)*pos_entropy + (no/total)*neg_entropy)
        
def gain(a):
  pos_sum = sum([othertable[i][0] for i in range(len(othertable))])
  neg_sum = sum([othertable[i][0] == 0 for i in range(len(othertable))])
  p_entropy = B(pos_sum/(pos_sum+neg_sum))
  return p_entropy - remainder(a)


def decision_stump():
  print("======= Root =======\nDem: %d Rep: %d" % (neg[0], pos[0]))
  
  for a in range(16):
    dem_predict = "No"
    rep_predict = "No"
    print("\n========= attribute %d============" % (a+2))
    print("gain:", gain(a+1))
    print("Yes: %d No: %d" % (pos[a+1],neg[a+1]))
    print("Dem_Yes: %d Dem_No: %d Rep_Yes: %d Rep_No: %d" % (dem_pos[a+1], dem_neg[a+1], rep_pos[a+1], rep_neg[a+1]))
    if(dem_pos[a+1] >= dem_neg[a+1]):
      dem_predict = "Yes"
    if(rep_pos[a+1] >= rep_neg[a+1]):
      rep_predict = "Yes"
    print("Predict:\nDem: %s Rep: %s" % (dem_predict, rep_predict))

dem_pos = []
dem_neg = []
rep_pos = []
rep_neg = []
for a in range(17):
  dem_pos.append(0)
  dem_neg.append(0)
  rep_pos.append(0)
  rep_neg.append(0)

classatt = range(17)
# count the positive, negative examples for classication and each attribute
pos=[ sum([othertable[j][i]    for j in range(len(othertable))]) for i in classatt ] 
neg=[ sum([othertable[j][i]==0 for j in range(len(othertable))]) for i in classatt ] 

decision_stump()